下面的序号表示scrapy执行步骤：

- 引擎
    - 主要来触发事务的，去实例化对象，去对象中调用实例化对象的方法和属性
    ④ 调度器调度到一个请求对象，把请求对象发送给引擎，引擎再次把请求对象的请求发送给下载器
    ⑦ 引擎会再把response返还给Spider
    ⑩ 引擎把拿到的Item数据提交到管道
- Spider
    spider指的是爬虫文件
        - url的输入获取
            ① 把url封装成请求对象，发送给引擎，引擎再把请求对象转发送给调度器
        数据解析
            ⑧ Spider的解析数据的函数接收到response对其进行解析
            ⑨ 把解析好的数据存储到Item当中，然后把Item提交给引擎
- 调度器
    - 过滤器
        ② 讲引擎发送给调度器的请求对象进行过滤去重
    - 队列
        ③ 把过滤好的请求对象放在队列里，调取器从请求队列当中去请求数据
- 管道
    ①① 管道拿到解析后的item数据进行提取，再把数据持久化存储
- 下载器
    - 整个异步是在下载器这边实现的，会同时调去多个请求下载任务
    ⑤ 下载器会根据请求对象，会去互联网中请求下载数据
    ⑥ 下载器获取到互联网返回的response，下载器会把response返回给引擎